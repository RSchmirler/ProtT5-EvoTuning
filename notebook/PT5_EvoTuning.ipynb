{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "050d7dd4",
   "metadata": {
    "id": "050d7dd4"
   },
   "source": [
    "# ProtT5 Evo-Tuning\n",
    "\n",
    "This notebook allows you to continue the unsupervised pre-training for [ProtT5](https://github.com/agemagician/ProtTrans).\n",
    "\n",
    "In this example we show how to [evo-tune](https://www.nature.com/articles/s41592-019-0598-1) the model for the [GFP](https://www.uniprot.org/uniprotkb/P42212/entry) protein using a MSA (homolgo sequences to GFP) as training data.\n",
    "\n",
    "For better perfomance we apply [Parameter-Efficient Fine-Tuning (PEFT)](https://huggingface.co/blog/peft). For this we apply [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685).\n",
    "\n",
    "The core training loop is implemented with the pytorch [huggingface trainer](https://huggingface.co/docs/transformers/main_classes/trainer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde58a20",
   "metadata": {
    "id": "dde58a20"
   },
   "source": [
    "## Imports and env. variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-toronto",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23587,
     "status": "ok",
     "timestamp": 1737466559297,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "angry-toronto",
    "outputId": "63297716-80e8-4dd1-8cf3-9e92d8826805"
   },
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import os.path\n",
    "\n",
    "#set path\n",
    "os.chdir(\"./to_your_path\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "\n",
    "from transformers import T5Tokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import GenerationConfig\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from typing import Optional, Tuple, Union, Any, List, NewType, Callable, Dict\n",
    "from collections.abc import Mapping\n",
    "\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "\n",
    "import peft\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, LoraConfig, get_peft_model\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e21e96",
   "metadata": {
    "id": "24e21e96"
   },
   "source": [
    "# Environment to run this notebook\n",
    "\n",
    "\n",
    "These are the versions of the core packages we use to run this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ccc1eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737466559298,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "b2ccc1eb",
    "outputId": "85a5e0f5-74ea-4b33-c6e8-49c126bd2847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  1.13.1\n",
      "Cuda version:  11.7\n",
      "Numpy version:  1.22.3\n",
      "Pandas version:  1.5.3\n",
      "Transformers version:  4.47.1\n",
      "Datasets version:  2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c5a63",
   "metadata": {
    "id": "9f0c5a63"
   },
   "source": [
    "# Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f9c1d5",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1737466559298,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "37f9c1d5"
   },
   "outputs": [],
   "source": [
    "checkpoint = \"Rostlab/prot_t5_xl_uniref50\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2dda19",
   "metadata": {
    "id": "fb2dda19"
   },
   "source": [
    "# Input data\n",
    "\n",
    "We load two files:\n",
    "\n",
    "\n",
    "\n",
    "1.   A MSA fasta file holding homologs to the wildtype GFP sequence\n",
    "2.   A csv-file holding randomly selected SwissProt entries, which we use as additional validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9584b17b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1737466559520,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "9584b17b",
    "outputId": "0bbcbd18-42f8-423a-b8f7-304065b39aa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UniRef90_A0A4S2H6I4_1.0</td>\n",
       "      <td>NILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLAD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UniRef90_UPI001C43669A_1.0</td>\n",
       "      <td>MTMITPSLHACRSTLEDPRVPVEKMSKGEELFTGVVPILVELDGDV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniRef90_UPI0000D5BE54_0.999</td>\n",
       "      <td>MASKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UniRef90_UPI00022F83CA_0.993</td>\n",
       "      <td>MRGSHHHHHHGMASMTGGQQMGRDLYDDDDKDRWGSKIEEGKLVIW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UniRef90_A0A1V4T0E4_0.993</td>\n",
       "      <td>MRDPASKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0       UniRef90_A0A4S2H6I4_1.0   \n",
       "1    UniRef90_UPI001C43669A_1.0   \n",
       "2  UniRef90_UPI0000D5BE54_0.999   \n",
       "3  UniRef90_UPI00022F83CA_0.993   \n",
       "4     UniRef90_A0A1V4T0E4_0.993   \n",
       "\n",
       "                                            sequence  \n",
       "0  NILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLAD...  \n",
       "1  MTMITPSLHACRSTLEDPRVPVEKMSKGEELFTGVVPILVELDGDV...  \n",
       "2  MASKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLK...  \n",
       "3  MRGSHHHHHHGMASMTGGQQMGRDLYDDDDKDRWGSKIEEGKLVIW...  \n",
       "4  MRDPASKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKL...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "#1: GFP MSA sequences with 85 homolog sequences\n",
    "# GFP wildtye entry: https://www.uniprot.org/uniprotkb/P42212/entry\n",
    "# Load training sequences\n",
    "url = 'https://raw.githubusercontent.com/RSchmirler/ProtT5-EvoTuning/refs/heads/main/data/GFP_AEQVI_MSA.fasta'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "# Create a StringIO object to simulate a file-like object\n",
    "fasta_file = StringIO(response.text)\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "sequences = []\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    sequences.append([record.name, str(record.seq)])\n",
    "\n",
    "# Create dataframe\n",
    "df_gfp = pd.DataFrame(sequences, columns=[\"name\", \"sequence\"])\n",
    "df_gfp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FF2fofkEw_Kl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1737466560076,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "FF2fofkEw_Kl",
    "outputId": "eb310222-bbd3-4c43-d4c2-77bd6798d887"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Length</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9S736</td>\n",
       "      <td>OBE1_ARATH</td>\n",
       "      <td>Arabidopsis thaliana (Mouse-ear cress)</td>\n",
       "      <td>566</td>\n",
       "      <td>MGTSSGSNLPHQMLPPRQQLQTSLSLVSSDPHLSRSNSGIVRESPA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9Y0Y0</td>\n",
       "      <td>CECB1_AEDAL</td>\n",
       "      <td>Aedes albopictus (Asian tiger mosquito) (Stego...</td>\n",
       "      <td>60</td>\n",
       "      <td>MNFNKLFALVLLIGLVLLTGQTEAGGLKKLGKKLEGVGKRVFKASE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B8NNN3</td>\n",
       "      <td>AP1_ASPFN</td>\n",
       "      <td>Aspergillus flavus (strain ATCC 200026 / FGSC ...</td>\n",
       "      <td>584</td>\n",
       "      <td>MADYNTLYHQGLYLSPDQQDLLLAALSSNQPPQKQQNDKQRSQAKT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q8K0E3</td>\n",
       "      <td>SC5AB_MOUSE</td>\n",
       "      <td>Mus musculus (Mouse)</td>\n",
       "      <td>673</td>\n",
       "      <td>MESATISPQPPQSDSLEAFPQKSMEPADIAVLVLYFLFVLAVGLWS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O42906</td>\n",
       "      <td>GPN1_SCHPO</td>\n",
       "      <td>Schizosaccharomyces pombe (strain 972 / ATCC 2...</td>\n",
       "      <td>367</td>\n",
       "      <td>MTDKEKKPCAIIVVGMAGSGKTTFMQQLNAHLHSKNKPPYILNLDP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entry   Entry Name                                           Organism  \\\n",
       "0  Q9S736   OBE1_ARATH             Arabidopsis thaliana (Mouse-ear cress)   \n",
       "1  Q9Y0Y0  CECB1_AEDAL  Aedes albopictus (Asian tiger mosquito) (Stego...   \n",
       "2  B8NNN3    AP1_ASPFN  Aspergillus flavus (strain ATCC 200026 / FGSC ...   \n",
       "3  Q8K0E3  SC5AB_MOUSE                               Mus musculus (Mouse)   \n",
       "4  O42906   GPN1_SCHPO  Schizosaccharomyces pombe (strain 972 / ATCC 2...   \n",
       "\n",
       "   Length                                           sequence  \n",
       "0     566  MGTSSGSNLPHQMLPPRQQLQTSLSLVSSDPHLSRSNSGIVRESPA...  \n",
       "1      60  MNFNKLFALVLLIGLVLLTGQTEAGGLKKLGKKLEGVGKRVFKASE...  \n",
       "2     584  MADYNTLYHQGLYLSPDQQDLLLAALSSNQPPQKQQNDKQRSQAKT...  \n",
       "3     673  MESATISPQPPQSDSLEAFPQKSMEPADIAVLVLYFLFVLAVGLWS...  \n",
       "4     367  MTDKEKKPCAIIVVGMAGSGKTTFMQQLNAHLHSKNKPPYILNLDP...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2: Random subset of ~1100 SwissProt sequences\n",
    "\n",
    "# Load training sequences\n",
    "url = 'https://raw.githubusercontent.com/RSchmirler/ProtT5-EvoTuning/refs/heads/main/data/swissprot_protein_level_subset.tsv'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "# Create a StringIO object to simulate a file-like object\n",
    "tsv_file = StringIO(response.text)\n",
    "\n",
    "# Load the TSV content into a pandas DataFrame\n",
    "df_swissprot = pd.read_csv(tsv_file, sep='\\t')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_swissprot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c012178",
   "metadata": {
    "id": "3c012178"
   },
   "source": [
    "**Modify the data loading part above as needed for your data**\n",
    "\n",
    "Each dataset should contain a **sequence** column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b996723",
   "metadata": {
    "id": "4b996723"
   },
   "source": [
    "# Models and Low Rank Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0e7b7",
   "metadata": {
    "id": "14c0e7b7"
   },
   "source": [
    "## T5 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "split-austin",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737466560077,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "split-austin"
   },
   "outputs": [],
   "source": [
    "def load_T5_model(checkpoint):\n",
    "\n",
    "    # Load model and tokenizer\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, force_download=False)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(checkpoint, force_download=False)\n",
    "\n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"T5_EncDec\\nTrainable Parameter: \"+ str(params))\n",
    "\n",
    "    # lora modification\n",
    "    peft_config = LoraConfig(\n",
    "        r=4, lora_alpha=1, bias=\"all\", target_modules=[\"q\",\"k\",\"v\",\"o\"], task_type = \"SEQ_2_SEQ_LM\",\n",
    "    )\n",
    "\n",
    "    # create peft SEQ_2_SEQ_LM model\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "    # Print trainable Parameter\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"T5_LoRA_EncDec\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-yeast",
   "metadata": {
    "id": "beautiful-yeast"
   },
   "source": [
    "# Training Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92962861",
   "metadata": {
    "id": "92962861"
   },
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ui0UoOrY2Y9Z",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737466560077,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "ui0UoOrY2Y9Z"
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters\n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "\n",
    "def load_model(checkpoint, filepath):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load model\n",
    "    model, tokenizer = load_T5_model(checkpoint)\n",
    "\n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hOEhiuR2z2aG",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737466560077,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "hOEhiuR2z2aG"
   },
   "outputs": [],
   "source": [
    "def shift_right(input_ids):\n",
    "    decoder_start_token_id = 0\n",
    "    pad_token_id = 0\n",
    "\n",
    "    shifted_input_ids = torch.full(input_ids.shape[:-1] + (1,), decoder_start_token_id)\n",
    "    shifted_input_ids = torch.cat([shifted_input_ids, input_ids[..., :-1]], dim=-1)\n",
    "\n",
    "    return shifted_input_ids\n",
    "\n",
    "\n",
    "def pad_without_fast_tokenizer_warning(tokenizer, *pad_args, **pad_kwargs):\n",
    "    \"\"\"\n",
    "    Pads without triggering the warning about how using the pad function is sub-optimal when using a fast tokenizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # To avoid errors when using Feature extractors\n",
    "    if not hasattr(tokenizer, \"deprecation_warnings\"):\n",
    "        return tokenizer.pad(*pad_args, **pad_kwargs)\n",
    "\n",
    "    # Save the state of the warning, then disable it\n",
    "    warning_state = tokenizer.deprecation_warnings.get(\"Asking-to-pad-a-fast-tokenizer\", False)\n",
    "    tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
    "\n",
    "    try:\n",
    "        padded = tokenizer.pad(*pad_args, **pad_kwargs)\n",
    "    finally:\n",
    "        # Restore the state of the warning.\n",
    "        tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = warning_state\n",
    "\n",
    "    return padded\n",
    "\n",
    "class T5DataCollatorForPretraining(DataCollatorForLanguageModeling):\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "\n",
    "        # Handle dict or lists with proper padding and conversion to tensor.\n",
    "        if isinstance(examples[0], Mapping):\n",
    "            batch = pad_without_fast_tokenizer_warning(\n",
    "                self.tokenizer, examples, return_tensors=\"pt\", pad_to_multiple_of=self.pad_to_multiple_of\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            batch = {\n",
    "                \"input_ids\": _torch_collate_batch(examples, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
    "            }\n",
    "\n",
    "        # If special token mask has been preprocessed, pop it from the dict.\n",
    "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
    "        if self.mlm:\n",
    "            batch[\"input_ids\"], batch[\"labels\"], batch[\"decoder_input_ids\"] = self.torch_mask_tokens(\n",
    "                batch[\"input_ids\"], special_tokens_mask=special_tokens_mask\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            labels = batch[\"input_ids\"].clone()\n",
    "            if self.tokenizer.pad_token_id is not None:\n",
    "                labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "            batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "    def torch_mask_tokens(self, inputs: Any, special_tokens_mask: Optional[Any] = None) -> Tuple[Any, Any, Any]:\n",
    "        \"\"\"\n",
    "        Prepare masked tokens inputs/labels for masked language modeling: 100% MASK\n",
    "        \"\"\"\n",
    "        labels = inputs.clone()\n",
    "        # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
    "        probability_matrix = torch.full(labels.shape, self.mlm_probability)\n",
    "        if special_tokens_mask is None:\n",
    "            special_tokens_mask = [\n",
    "                self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "            ]\n",
    "            special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "        else:\n",
    "            special_tokens_mask = special_tokens_mask.bool()\n",
    "\n",
    "        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "        # Create decoder inputs\n",
    "        decoder_inputs = shift_right(inputs)\n",
    "\n",
    "        # For ProtT5 pre-training we replace ALL masked input tokens with tokenizer.mask_token ([MASK])\n",
    "        inputs[masked_indices] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "\n",
    "        return inputs, labels, decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liberal-learning",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1737466560077,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -60
    },
    "id": "liberal-learning"
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs):\n",
    "\n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=False, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        checkpoint,       #model checkpoint\n",
    "        train_df,         #training data (GFP MSA)\n",
    "        valid_df,         #validation data (Swiss-Prot subset)\n",
    "\n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8\n",
    "        batch = 4,        #for training\n",
    "        accum = 2,        #gradient accumulation\n",
    "\n",
    "        val_batch = 1,   #batch size for evaluation\n",
    "        epochs = 10,      #training epochs\n",
    "        lr = 3e-4,        #recommended learning rate\n",
    "        seed = 42,        #random seed\n",
    "        mixed = True,     #enable mixed precision training\n",
    "        gpu = 1 ):        #gpu selection (1 for first gpu)\n",
    "\n",
    "\n",
    "    print(\"Model used:\", checkpoint, \"\\n\")\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "\n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "\n",
    "    # load model\n",
    "    model, tokenizer = load_T5_model(checkpoint)\n",
    "\n",
    "    #provide the mask token, not the id\n",
    "    tokenizer.mask_token = \"<extra_id_0>\"\n",
    "\n",
    "    # Preprocess inputs\n",
    "    # Replace uncommon AAs with \"X\"\n",
    "    train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"J\"]),\"X\",regex=True)\n",
    "    valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"J\"]),\"X\",regex=True)\n",
    "\n",
    "    # Add spaces between each amino acid for ProtT5 and ProstT5 to correctly use them\n",
    "    train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "    valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "    # Create Datasets (tokenize labels as well)\n",
    "    train_set=create_dataset(tokenizer,list(train_df['sequence']))\n",
    "    valid_set=create_dataset(tokenizer,list(valid_df['sequence']))\n",
    "\n",
    "    # Create a dict to use both datasets for evaluation\n",
    "    val_dict = {\"Swiss-Prot\": valid_set, \"GFP-MSA\": train_set}\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        \"./\",\n",
    "        eval_strategy = \"steps\",\n",
    "        eval_steps = 20,\n",
    "        logging_strategy = \"epoch\",\n",
    "        save_strategy = \"no\",\n",
    "        learning_rate = lr,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        warmup_steps = 0,\n",
    "        per_device_train_batch_size=batch,\n",
    "        per_device_eval_batch_size=val_batch,\n",
    "        gradient_accumulation_steps=accum,\n",
    "        num_train_epochs=epochs,\n",
    "        seed = seed,\n",
    "        fp16 = mixed,\n",
    "    )\n",
    "\n",
    "    # Metric definition for validation data\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        # Unpack logits and labels from EvalPrediction\n",
    "        logits_tuple, labels = eval_pred\n",
    "        # Select the first element, assuming it's the logits\n",
    "\n",
    "        logits = logits_tuple[0]\n",
    "\n",
    "        # Convert logits and labels to tensors\n",
    "        logits_tensor = torch.tensor(logits, dtype=torch.float32)\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        # Initialize the mask to select only predictions where labels are not -100\n",
    "        mask = labels_tensor != -100\n",
    "\n",
    "        # Select only the masked elements\n",
    "        masked_logits = logits_tensor[mask].view(-1, logits_tensor.shape[-1])\n",
    "        masked_labels = labels_tensor[mask].view(-1)\n",
    "\n",
    "        # Calculate the loss for masked tokens\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        loss = loss_fn(masked_logits, masked_labels)\n",
    "\n",
    "        # Compute the average loss\n",
    "        average_loss = loss.mean().item()\n",
    "\n",
    "        # Perplexity is the exponential of the average cross-entropy loss\n",
    "        perplexity = np.exp(average_loss)\n",
    "\n",
    "        # Calculate accuracy (correct demasking)\n",
    "        # Get the predicted tokens by finding the index of the max logit\n",
    "        _, predicted_tokens = torch.max(masked_logits, dim=-1)\n",
    "        # Compare predicted tokens with actual tokens and compute accuracy\n",
    "        correct_predictions = (predicted_tokens == masked_labels).sum().item()\n",
    "        accuracy = correct_predictions / masked_labels.size(0)\n",
    "\n",
    "        return {\"perplexity\": perplexity, \"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "    data_collator = T5DataCollatorForPretraining(tokenizer,checkpoint)\n",
    "\n",
    "    #define device\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #create dir for saving model checkpoints\n",
    "    os.makedirs(\"./checkpoints\")\n",
    "\n",
    "    #custom callback to save model\n",
    "    class SaveCallback(TrainerCallback):\n",
    "        def on_epoch_end(self, args, state, control, logs=None, **kwargs):\n",
    "\n",
    "                if (int(state.epoch) % 2 == 0) and int(state.epoch) != 0:\n",
    "                    inf_model=kwargs['model'].to(device)\n",
    "                    inf_model.eval()\n",
    "\n",
    "                    #save_model\n",
    "                    save_model(inf_model, \"./checkpoints/GFP_EvoTuning_step_\" + str(int(state.global_step)) + \".pth\")\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=val_dict,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[SaveCallback()]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac94ab1",
   "metadata": {
    "id": "5ac94ab1"
   },
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede09d5",
   "metadata": {
    "id": "4ede09d5"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3bbc2c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "id": "b3bbc2c4",
    "outputId": "3d08b1b1-d8b1-4613-c1db-e98e0454032f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: Rostlab/prot_t5_xl_uniref50 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5_EncDec\n",
      "Trainable Parameter: 2818830336\n",
      "T5_LoRA_EncDec\n",
      "Trainable Parameter: 5900288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 32:25, Epoch 27/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Swiss-prot Loss</th>\n",
       "      <th>Swiss-prot Perplexity</th>\n",
       "      <th>Swiss-prot Accuracy</th>\n",
       "      <th>Gfp-msa Loss</th>\n",
       "      <th>Gfp-msa Perplexity</th>\n",
       "      <th>Gfp-msa Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>17.131900</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.195288</td>\n",
       "      <td>3.210354</td>\n",
       "      <td>0.643921</td>\n",
       "      <td>2.167026</td>\n",
       "      <td>6.438691</td>\n",
       "      <td>0.423091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>16.978300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.192221</td>\n",
       "      <td>3.168258</td>\n",
       "      <td>0.647096</td>\n",
       "      <td>2.172364</td>\n",
       "      <td>6.538612</td>\n",
       "      <td>0.419545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>17.045400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.174747</td>\n",
       "      <td>3.180949</td>\n",
       "      <td>0.637874</td>\n",
       "      <td>2.119353</td>\n",
       "      <td>6.179417</td>\n",
       "      <td>0.441455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>16.572700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.196288</td>\n",
       "      <td>3.204035</td>\n",
       "      <td>0.641870</td>\n",
       "      <td>2.084691</td>\n",
       "      <td>6.046345</td>\n",
       "      <td>0.450380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>15.930100</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.201769</td>\n",
       "      <td>3.241283</td>\n",
       "      <td>0.635920</td>\n",
       "      <td>1.925049</td>\n",
       "      <td>5.288980</td>\n",
       "      <td>0.484881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>15.266600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.192252</td>\n",
       "      <td>3.245801</td>\n",
       "      <td>0.635460</td>\n",
       "      <td>1.720150</td>\n",
       "      <td>4.569580</td>\n",
       "      <td>0.532261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>13.704800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.179757</td>\n",
       "      <td>3.163413</td>\n",
       "      <td>0.643181</td>\n",
       "      <td>1.497226</td>\n",
       "      <td>3.817971</td>\n",
       "      <td>0.591442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>12.054100</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.190167</td>\n",
       "      <td>3.252241</td>\n",
       "      <td>0.639440</td>\n",
       "      <td>1.306638</td>\n",
       "      <td>3.288134</td>\n",
       "      <td>0.642597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>10.750900</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.199766</td>\n",
       "      <td>3.200798</td>\n",
       "      <td>0.642244</td>\n",
       "      <td>1.154923</td>\n",
       "      <td>2.947627</td>\n",
       "      <td>0.673882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.986900</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.206415</td>\n",
       "      <td>3.208712</td>\n",
       "      <td>0.635995</td>\n",
       "      <td>1.092010</td>\n",
       "      <td>2.775202</td>\n",
       "      <td>0.694531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>9.723700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.246272</td>\n",
       "      <td>3.307376</td>\n",
       "      <td>0.628266</td>\n",
       "      <td>1.034873</td>\n",
       "      <td>2.686316</td>\n",
       "      <td>0.708064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>9.224200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.217201</td>\n",
       "      <td>3.226671</td>\n",
       "      <td>0.639278</td>\n",
       "      <td>1.014712</td>\n",
       "      <td>2.588299</td>\n",
       "      <td>0.714028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>9.172400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.227395</td>\n",
       "      <td>3.304282</td>\n",
       "      <td>0.628863</td>\n",
       "      <td>1.021721</td>\n",
       "      <td>2.620494</td>\n",
       "      <td>0.716404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>9.089500</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.199181</td>\n",
       "      <td>3.179673</td>\n",
       "      <td>0.637006</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>2.479756</td>\n",
       "      <td>0.732104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.792800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.216174</td>\n",
       "      <td>3.240359</td>\n",
       "      <td>0.637364</td>\n",
       "      <td>0.983489</td>\n",
       "      <td>2.566488</td>\n",
       "      <td>0.724189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(checkpoint, df_gfp, df_swissprot, batch = 1, accum = 8, epochs = 30, seed = 42, mixed = False, gpu=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bab485",
   "metadata": {
    "id": "54bab485"
   },
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8465267",
   "metadata": {
    "id": "f8465267"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "\n",
    "metric = [x['eval_Swiss-Prot_perplexity'] for x in history if 'eval_Swiss-Prot_perplexity' in x]\n",
    "metric2 = [x['eval_GFP-MSA_perplexity'] for x in history if 'eval_GFP-MSA_perplexity' in x]\n",
    "\n",
    "acc = [x['eval_Swiss-Prot_accuracy'] for x in history if 'eval_Swiss-Prot_accuracy' in x]\n",
    "acc2 = [x['eval_GFP-MSA_accuracy'] for x in history if 'eval_GFP-MSA_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "epochsv = [x['epoch'] for x in history if 'eval_Swiss-Prot_perplexity' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, color=\"orange\", label='train_loss')\n",
    "line2 = ax1.plot(epochsv, metric2, color='coral', label='GFP_perplexity')\n",
    "line3 = ax1.plot(epochsv, metric, color='darkred', label='SwissProt_perplexity')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss / Perplexity')\n",
    "\n",
    "# Plot the computed metric on the second y-axisload_model\n",
    "line4 = ax2.plot(epochsv, acc, color='royalblue', label='SwissProt_accuracy')\n",
    "line5 = ax2.plot(epochsv, acc2, color='cyan', label='GFP_accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 + line5 + line3 + line4\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History - ProtT5 - GFP EvoTuning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4a53e",
   "metadata": {
    "id": "c7a4a53e"
   },
   "source": [
    "# Load the EvoTuned GFP-model and merge adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ade4a9d",
   "metadata": {
    "id": "6ade4a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5_EncDec\n",
      "Trainable Parameter: 2818830336\n",
      "T5_LoRA_EncDec\n",
      "Trainable Parameter: 5900288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load one of the saved model checkpoints\n",
    "tokenizer, model = load_model(checkpoint, \"./checkpoints/GFP_EvoTuning_step_286.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edbd69f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1724748880692,
     "user": {
      "displayName": "Robert S.",
      "userId": "15925788058961757968"
     },
     "user_tz": -120
    },
    "id": "edbd69f7",
    "outputId": "d056c143-2627-4771-a885-f4486ea00c9f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unloading and merging model: 100%|| 1357/1357 [00:00<00:00, 1375.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional:\n",
    "# merge the trained LoRA adapter into the original model\n",
    "# this can be useful to continue working with the Evo-Tuned model (e.g. for fine-tuning it on some downstream task)\n",
    "model.cpu().merge_and_unload('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bff8e4-25ae-4628-b0e4-51b0b4641c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb",
     "timestamp": 1670229986129
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-finetune]",
   "language": "python",
   "name": "conda-env-.conda-finetune-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
